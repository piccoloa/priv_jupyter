{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Applying Sentiment analysis to movie review using Kaggle labeled dataset.\n",
    "\n",
    "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment model classification based on labled Kaggle dataset  \n",
    "\n",
    "\n",
    "## Part 2-Create, Test & Save Sentiment Model\n",
    "__Summary__:  \n",
    "\n",
    "\n",
    "Create a sentiment analysis algorithm using labeled kaggle movie reviews.  Part 1 cleaned and saved reviews to a database. This post adjusts the Kaggle dataset to comply with a binary classification, in which the target variable only has two classes to be predicted. For this post, the classes are either “negative” or “positive”. Labeled reviews are marked as either a __positive__(> 3) or __negative__(<3) movie review. The Kaggle dataset reviews are labeled as 0 - 4 (neg - pos) based on the training set.  \n",
    "In short, the NLTK library is used to extract POS (parts-of-speech- adjectives) from reviews to use as __features__ for each movie review. These featuresets are then used to train the sentiment models.  The feature sets associated with the labeled reviews are measured against a bag-of-words to calculate the likelihood of the review being categorized as a positive or negative sentiment.  \n",
    "\n",
    "Combining classifier algorithms is a common technique, done by creating a sort of voting system, where each algorithm gets one vote, and the classification that has the most votes is the chosen one.  In NLTK, classifiers are defined using classes that implement the ClassifyI interface. A processing interface for labeling tokens with a single category label (or \"class\"). Labels are typically strings or integers, but can be any immutable type. The set of labels that the classifier chooses from must be fixed and finite.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.  Create two tables, one for negative reviews and one for positive reviews. \n",
    "2.  Use NLTK to tokenize phrases, create featuresets, and test Scikitlearn classificaion models.   \n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python3.6\n",
    "#import logging\n",
    "import os\n",
    "import pyodbc\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postgres authentication\n",
    "user = \"alexp\"\n",
    "password = \"secret\"\n",
    "host = \"pg_db\"\n",
    "port = \"5432\"\n",
    "database = \"priv_workspace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'alexp', 'dbname': 'priv_workspace', 'host': 'pg_db', 'port': '5432', 'tty': '', 'options': '', 'sslmode': 'prefer', 'sslcompression': '1', 'krbsrvname': 'postgres'} \n",
      "\n",
      "You are connected to -  ('PostgreSQL 10.5 (Debian 10.5-1.pgdg90+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 6.3.0-18+deb9u1) 6.3.0 20170516, 64-bit',) \n",
      "\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "#view pg environment\n",
    "try:\n",
    "    connection = psycopg2.connect(user = user,\n",
    "                                  password = password,\n",
    "                                  host = host,\n",
    "                                  port = port,\n",
    "                                  database = database)\n",
    "    cursor = connection.cursor()\n",
    "    # Print PostgreSQL Connection properties\n",
    "    print ( connection.get_dsn_parameters(),\"\\n\")\n",
    "    # Print PostgreSQL version\n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    record = cursor.fetchone()\n",
    "    print(\"You are connected to - \", record,\"\\n\")\n",
    "except (Exception, psycopg2.Error) as error :\n",
    "    print (\"Error while connecting to PostgreSQL\", error)\n",
    "finally:\n",
    "    #closing database connection.\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Create two tables, one for negative reviews and one for positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table of full sentences \n",
    "sql1 = '''\n",
    "SELECT phrase\n",
    "FROM \"sent_train_tble\"\n",
    "where sentiment < 2\n",
    "'''\n",
    "sql2 = '''\n",
    "SELECT phrase\n",
    "FROM \"sent_train_tble\"\n",
    "where sentiment > 3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativefilename = 'negative.txt'\n",
    "positivefilename = 'positive.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created file negative.txt\n",
      "created file positive.txt\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "#SAVE TO QUERY TO TEXT FILES\n",
    "from psycopg2 import Error\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(user = user,\n",
    "                                  password = password,\n",
    "                                  host = host,\n",
    "                                  port = port,\n",
    "                                  database = database)\n",
    "    cursor = connection.cursor()\n",
    "    connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    engine_string = \"postgresql://{}:{}@{}:{}/{}\".format(user, password, host, port, database)\n",
    "    engine = create_engine(engine_string)\n",
    "    \n",
    "    outputquery = \"COPY ({0}) TO STDOUT WITH CSV HEADER\".format(sql1)\n",
    "        \n",
    "    with open(negativefilename, 'w') as f:\n",
    "        cursor.copy_expert(outputquery, f)\n",
    "    \n",
    "    print('created file', negativefilename)\n",
    "    \n",
    "    outputquery = \"COPY ({0}) TO STDOUT WITH CSV HEADER\".format(sql2)\n",
    "        \n",
    "    with open(positivefilename, 'w') as f:\n",
    "        cursor.copy_expert(outputquery, f)\n",
    "    \n",
    "    print('created file', positivefilename)    \n",
    "\n",
    "\n",
    "except (Exception, psycopg2.DatabaseError) as error :\n",
    "    print (\"Error while creating PostgreSQL table\", error)\n",
    "finally:\n",
    "    #closing database connection.\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.  Use NLTK to tokenize phrases, create featuresets, and test Scikitlearn classificaion models.\n",
    "***details of function find_features(document)***   \n",
    "creates an array of the top 5000 most frequent words that are in each of the notes already classified as pos or neg.  \n",
    "each of the top 5k words in note is assigned a booleen values:   \n",
    "({\n",
    "'flat': False, 'horizontal': False, 'library': False...},'pos'), <br\\>\n",
    "({'flat': False, 'horizontal':  False, 'library': False...},'pos')...<br\\>\n",
    "]  \n",
    "\n",
    "##### This process needs to be completed load each time new reviews that are categorized are to be used for a new recalibrated training set\n",
    "\n",
    "Documents, all features frequencies and top 5000 features frequencies for training set are stored to pickle files for saving each classifier model and allow reduce the amount of time to process the saved sentiment model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates documents list with class and all_words (using part of speech nltk for filtering only\n",
    "# adjectives for a list to to use as features for creating classification\n",
    "#filepath\n",
    "negativefilename = 'negative.txt'\n",
    "positivefilename = 'positive.txt'\n",
    "\n",
    "#opens local files\n",
    "short_pos = open(str(positivefilename), 'r', encoding=\"utf8\").read()\n",
    "short_neg = open(str(negativefilename), 'r', encoding=\"utf8\").read()\n",
    "\n",
    "#splits each line in each file, appends text 'pos' and 'neg' to line added to created documents list\n",
    "documents = []\n",
    "all_words = []\n",
    "\n",
    "#  j is adjective, r is adverb, and v is verb\n",
    "#allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "allowed_word_types = [\"J\"]\n",
    "# appending to docoments for training and test classificaton and creating all_words for all features to be tested\n",
    "for p in short_pos.split('\\n'):            #splits on new rows then loops by split\n",
    "    documents.append( (p, \"pos\") )         #each split adds review and 'pos'\n",
    "    words = word_tokenize(p)               #word tokenize each p\n",
    "    exclude = set(string.punctuation)\n",
    "    clean = [\"''\", '``']\n",
    "    words = [w for w in words if w not in exclude and w.isalpha() and w not in clean]\n",
    "    #words = [w for w in words if w not in stopwords]\n",
    "    pos = nltk.pos_tag(words)              #uses function pos_tag for inner loop for words checking part of speech\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:    #need better understanding of w[1][0]\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "    \n",
    "for p in short_neg.split('\\n'):\n",
    "    documents.append( (p, \"neg\") )\n",
    "    words = word_tokenize(p)\n",
    "    exclude = set(string.punctuation)\n",
    "    clean = [\"''\", '``']\n",
    "    words = [w for w in words if w not in exclude and w.isalpha() and w not in clean]\n",
    "    #words = [w for w in words if w not in stopwords]\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:      #pos function tupple [1 is postive ??]\n",
    "            all_words.append(w[0].lower())\n",
    "            \n",
    "\n",
    "#dictionary with key and value of most commom to least common words\n",
    "all_words = nltk.FreqDist(all_words)             \n",
    "# limit the use of the only the top 5000 words in the all_words key value dictionary  {key = word, value=frequency}\n",
    "word_features = list(all_words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quiet', 'introspective', 'entertaining', 'independent', 'worth', 'epic', 'sincere', 'absolute', 'primary', 'memorable', 'best', 'lead', 'smart', 'provocative', 'impossible']\n"
     ]
    }
   ],
   "source": [
    "#saving documents to save processing time, this will be refreshed when training model is updated with new history\n",
    "save_documents = open(\"documents.pickle\",\"wb\")\n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "save_all_words = open(\"all_words_features.pickle\",\"wb\")\n",
    "pickle.dump(all_words, save_all_words)\n",
    "save_all_words.close()\n",
    "\n",
    "\n",
    "#save top 5k word features for training sets built below\n",
    "save_word_features = open(\"Algo_word_features5k.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()\n",
    "\n",
    "\n",
    "print(word_features[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### view of word features used after processing for:\n",
    "parts of speech classification and cleaing text for non alpha words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('more', 123), ('bad', 122), ('good', 121), ('funny', 91), ('little', 89), ('much', 89), ('best', 83), ('other', 70), ('many', 69), ('own', 68), ('most', 64), ('new', 54), ('first', 53), ('better', 52), ('great', 49)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_words_file = open(\"all_words_features.pickle\",\"rb\")\n",
    "all_words_features = pickle.load(all_words_file)\n",
    "print(all_words_features.most_common(15))\n",
    "fdist1 = FreqDist(all_words_features)\n",
    "fdist1.plot(25, cumulative=True)\n",
    "\n",
    "all_words_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***this must be run when model is updated***, this will save the updated featuresets to a file using the updated notes stored above that were saved to new pickled documents and word features.  \n",
    "the sentiment module is created by ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)  #creates booleen value each word in document(note) as either true or false \n",
    "\n",
    "    return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4557\n"
     ]
    }
   ],
   "source": [
    "#uses saved documents that are refreshed from source text files\n",
    "documents_file = open(\"documents.pickle\",\"rb\")\n",
    "documents = pickle.load(documents_file)\n",
    "featuresets = [(find_features(note), category) for (note, category) in documents]\n",
    "\n",
    "featuresets_f = open(\"features.pickle\",\"wb\")\n",
    "pickle.dump(featuresets, featuresets_f)\n",
    "featuresets_f.close()\n",
    "\n",
    "\n",
    "print(len(featuresets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below uses saved pickled object file as 'featurset_f' created with find_features fuction as input to choice of classification alogorithims from randomized sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening featuresets and creating training and test\n",
    "\n",
    "featuresets_f = open(\"features.pickle\",\"rb\")\n",
    "featuresets = pickle.load(featuresets_f)\n",
    "random.shuffle(featuresets)\n",
    "featuresets_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = featuresets[:4400]\n",
    "testing_set =  featuresets[4400:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***uses the nltk and Sklearn py modules for classification and saves the classifier to pickle files***<br\\>\n",
    "training and test sets are defined in previous cell using the featuresets stored from current current documents file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Combining Algorithms with NLTK and pickling to create a score for notes sentiment\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):   #passes a list of classifiers\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 82.80254777070064\n",
      "Most Informative Features\n",
      "               wonderful = True              pos : neg    =     23.0 : 1.0\n",
      "                touching = True              pos : neg    =     23.0 : 1.0\n",
      "                gorgeous = True              pos : neg    =     17.9 : 1.0\n",
      "              remarkable = True              pos : neg    =     16.2 : 1.0\n",
      "                    warm = True              pos : neg    =     16.2 : 1.0\n",
      "                     bad = True              neg : pos    =     16.2 : 1.0\n",
      "              thoughtful = True              pos : neg    =     14.8 : 1.0\n",
      "           extraordinary = True              pos : neg    =     12.8 : 1.0\n",
      "               beautiful = True              pos : neg    =     12.1 : 1.0\n",
      "                 delight = True              pos : neg    =     11.1 : 1.0\n",
      "                   vivid = True              pos : neg    =     11.1 : 1.0\n",
      "                terrific = True              pos : neg    =     10.7 : 1.0\n",
      "              delightful = True              pos : neg    =     10.7 : 1.0\n",
      "                    less = True              neg : pos    =     10.6 : 1.0\n",
      "                 crafted = True              pos : neg    =      9.7 : 1.0\n",
      "MNB_classifier accuracy percent: 82.16560509554141\n",
      "BernoulliNB_classifier accuracy percent: 83.43949044585987\n",
      "LogisticRegression_classifier accuracy percent: 78.343949044586\n",
      "LinearSVC_classifier accuracy percent: 82.16560509554141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier accuracy percent: 82.80254777070064\n",
      "voted_classifier accuracy percent: 81.52866242038218\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "save_classifier = open(\"pickled_algos_originalnaivebayes5k.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "######\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos_MNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "######\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos_BernoulliNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "######\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos_LogisticRegression_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "######\n",
    "\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos_LinearSVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "##NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "##NuSVC_classifier.train(training_set)\n",
    "##print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "SGDC_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDC_classifier.train(training_set)\n",
    "print(\"SGDClassifier accuracy percent:\",nltk.classify.accuracy(SGDC_classifier, testing_set)*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos_SGDC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(SGDC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "######\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the overall accuracy and better understand the accuarcy of positve verse negative predictions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### understand base predictions and the accruracy of positive verse negative sentiment predictions   \n",
    "This can be accomplished quickly by quering the db for the positive and negative text files created earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negativeCount= 3272\n",
      "base positve setiment=  0.2813529540962003\n",
      "postiveCount=  3272\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "#SAVE TO QUERY TO TEXT FILES\n",
    "from psycopg2 import Error\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(user = user,\n",
    "                                  password = password,\n",
    "                                  host = host,\n",
    "                                  port = port,\n",
    "                                  database = database)\n",
    "    cursor = connection.cursor()\n",
    "    connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    engine_string = \"postgresql://{}:{}@{}:{}/{}\".format(user, password, host, port, database)\n",
    "    engine = create_engine(engine_string)\n",
    "    \n",
    "    negativeCount = \"SELECT count(*) FROM sent_train_tble where sentiment < 2\"\n",
    "    cursor.execute(negativeCount)\n",
    "    negativeCount = cursor.fetchall()[0][0]\n",
    "    print('negativeCount=', negativeCount)\n",
    "    \n",
    "    postiveCount = \"SELECT count(*) FROM sent_train_tble where sentiment > 3\"\n",
    "    cursor.execute(postiveCount)\n",
    "    postiveCount = cursor.fetchall()[0][0]    \n",
    "    print(\"base positve setiment= \", postiveCount/(negativeCount+postiveCount))\n",
    "        \n",
    "    print('postiveCount= ', negativeCount)    \n",
    "\n",
    "\n",
    "except (Exception, psycopg2.DatabaseError) as error :\n",
    "    print (\"Error while creating PostgreSQL table\", error)\n",
    "finally:\n",
    "    #closing database connection.\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if one was to guess negative, they would be correct 72% of the time.  Using the algorithyms above, prediction accuracy is roughly 82%.  This is better than guessing.   Anything better than 72% accuracy for negative is better than guessing while accuracy in predicting a postive review needs to be better than 28%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** the prediction value is not as usefull for predicting positive movie ratings versus predicting negative ratings. that will be won considering 30% accuracy is low, while predicting deals that have negative sentiment with 85% accuracy is pretty good prediction)***<br \\>\n",
    "by not randomizing featuresets then testing 1st 100 which should be positive as documents were appended by pos then neg notes using saved classification models above\n",
    "\n",
    ">1.) opening featuresets without shuffling  \n",
    ">2.) creating training and test for postive docuents and to test accuracy of pos vs negative prediction in (similar to confusion matrix)  \n",
    ">3.) negative accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4557\n"
     ]
    }
   ],
   "source": [
    "#######to look at document order to confirm pos and negative order ##############\n",
    "# documents_f = open(str(filepath) + \"documents.pickle\",\"rb\")\n",
    "# documents = pickle.load(documents_f)\n",
    "# documents_f.close()\n",
    "# #print(documents[-100:]) #this shoud be a loop to look for 'neg' in documents\n",
    "\n",
    "#1\n",
    "featuresets_f = open(\"features.pickle\",\"rb\")\n",
    "featuresets = pickle.load(featuresets_f)\n",
    "#random.shuffle(featuresets)  this is to keep the order which is 1st hundred are positive vs last 100 negative\n",
    "featuresets_f.close()\n",
    "print(len(featuresets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy for predicting positive outcomes \n",
      " percent: 69.0\n",
      "Most Informative Features\n",
      "               wonderful = True              pos : neg    =     23.0 : 1.0\n",
      "                touching = True              pos : neg    =     23.0 : 1.0\n",
      "                gorgeous = True              pos : neg    =     17.9 : 1.0\n",
      "              remarkable = True              pos : neg    =     16.2 : 1.0\n",
      "                    warm = True              pos : neg    =     16.2 : 1.0\n",
      "                     bad = True              neg : pos    =     16.2 : 1.0\n",
      "              thoughtful = True              pos : neg    =     14.8 : 1.0\n",
      "           extraordinary = True              pos : neg    =     12.8 : 1.0\n",
      "               beautiful = True              pos : neg    =     12.1 : 1.0\n",
      "                 delight = True              pos : neg    =     11.1 : 1.0\n",
      "                   vivid = True              pos : neg    =     11.1 : 1.0\n",
      "                terrific = True              pos : neg    =     10.7 : 1.0\n",
      "              delightful = True              pos : neg    =     10.7 : 1.0\n",
      "                    less = True              neg : pos    =     10.6 : 1.0\n",
      "                 crafted = True              pos : neg    =      9.7 : 1.0\n",
      "MNB_classifier accuracy percent: 68.0\n",
      "BernoulliNB_classifier accuracy percent: 63.0\n",
      "LogisticRegression_classifier accuracy percent: 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 76.0\n",
      "LinearSVC_classifier accuracy percent: 79.0\n",
      "NuSVC_classifier accuracy percent: 46.0\n",
      "voted_classifier accuracy percent: 64.0\n"
     ]
    }
   ],
   "source": [
    "#2 positive data example:      \n",
    "training_set = featuresets[:4457]\n",
    "testing_set =  featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "classifier_f = open(\"pickled_algos_originalnaivebayes5k.pickle\",\"rb\")  \n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "\n",
    "print(\"Original Naive Bayes Algo accuracy for predicting positive outcomes \\n percent:\", \n",
    "      (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "##SVC_classifier = SklearnClassifier(SVC())\n",
    "##SVC_classifier.train(training_set)\n",
    "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy for predicting negative outcomes \n",
      " percent: 98.0\n",
      "Most Informative Features\n",
      "               wonderful = True              pos : neg    =     23.0 : 1.0\n",
      "                touching = True              pos : neg    =     23.0 : 1.0\n",
      "                gorgeous = True              pos : neg    =     17.9 : 1.0\n",
      "              remarkable = True              pos : neg    =     16.2 : 1.0\n",
      "                    warm = True              pos : neg    =     16.2 : 1.0\n",
      "                     bad = True              neg : pos    =     16.2 : 1.0\n",
      "              thoughtful = True              pos : neg    =     14.8 : 1.0\n",
      "           extraordinary = True              pos : neg    =     12.8 : 1.0\n",
      "               beautiful = True              pos : neg    =     12.1 : 1.0\n",
      "                 delight = True              pos : neg    =     11.1 : 1.0\n",
      "                   vivid = True              pos : neg    =     11.1 : 1.0\n",
      "                terrific = True              pos : neg    =     10.7 : 1.0\n",
      "              delightful = True              pos : neg    =     10.7 : 1.0\n",
      "                    less = True              neg : pos    =     10.6 : 1.0\n",
      "                 crafted = True              pos : neg    =      9.7 : 1.0\n",
      "MNB_classifier accuracy percent: 92.0\n",
      "BernoulliNB_classifier accuracy percent: 97.0\n",
      "LogisticRegression_classifier accuracy percent: 97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 94.0\n",
      "LinearSVC_classifier accuracy percent: 90.0\n",
      "NuSVC_classifier accuracy percent: 98.0\n",
      "voted_classifier accuracy percent: 97.0\n"
     ]
    }
   ],
   "source": [
    "#3 negative data example:      \n",
    "training_set = featuresets[:4457]\n",
    "testing_set =  featuresets[-100:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "classifier_f = open(\"pickled_algos_originalnaivebayes5k.pickle\",\"rb\")  \n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "\n",
    "print(\"Original Naive Bayes Algo accuracy for predicting negative outcomes \\n percent:\", \n",
    "      (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "##SVC_classifier = SklearnClassifier(SVC())\n",
    "##SVC_classifier.train(training_set)\n",
    "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Python Module that will be used on kaggle test reviews for sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sentiment_mod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentiment_mod.py\n",
    "#saved to file sentiment_mod.py\n",
    "import nltk\n",
    "import random\n",
    "#from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "\n",
    "documents_f = open(\"documents.pickle\", \"rb\")\n",
    "documents = pickle.load(documents_f)\n",
    "documents_f.close()\n",
    "\n",
    "\n",
    "word_features5k_f = open(\"Algo_word_features5k.pickle\", \"rb\")\n",
    "word_features = pickle.load(word_features5k_f)\n",
    "word_features5k_f.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "featuresets_f = open(\"features.pickle\", \"rb\")\n",
    "featuresets = pickle.load(featuresets_f)\n",
    "featuresets_f.close()\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "#print(len(featuresets))\n",
    "\n",
    "testing_set = featuresets[6900:]\n",
    "training_set = featuresets[:6900]\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos_originalnaivebayes5k.pickle\", \"rb\")\n",
    "classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos_MNB_classifier5k.pickle\", \"rb\")\n",
    "MNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos_BernoulliNB_classifier5k.pickle\", \"rb\")\n",
    "BernoulliNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos_LogisticRegression_classifier5k.pickle\", \"rb\")\n",
    "LogisticRegression_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos_LinearSVC_classifier5k.pickle\", \"rb\")\n",
    "LinearSVC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos_SGDC_classifier5k.pickle\", \"rb\")\n",
    "SGDC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "\n",
    "\n",
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', 1.0)\n",
      "('neg', 0.8)\n"
     ]
    }
   ],
   "source": [
    "import sentiment_mod as s\n",
    "\n",
    "#test the saved module against examples\n",
    "print(s.sentiment('''An intermittently pleasing but mostly routine effort .'''))\n",
    "print(s.sentiment('''Once you get bad its wonderful ... the movie wonderful a heady wonderful .'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(s.sentiment('''The story and structure are well-honed .'''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
